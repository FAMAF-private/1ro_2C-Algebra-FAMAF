Temas para el examen final

Definiciones

Equivalencia de sistemas lineales de ecuaciones.
Operaciones elementales de fila.
Equivalencia por filas de matrices.
Matriz reducida por fila (MRF) y matriz escalón reducida por fila (MERF).
Matrices elementales.
Matriz inversible.
Determinante de una matriz
Espacio vectorial
Subespacio vectorial.
Combinación lineal en un espacio vectorial.
Subespacio generado por un conjunto.
Suma de subespacios.
Conjuntos linealmente dependientes y conjuntos linealmente independientes.
Espacio vectorial de dimensión finita.
Dimensión de un espacio vectorial de dimensión finita.
Base ordenada de un espacio vectorial V.
Transformación lineal entre dos espacios vectoriales.
Núcleo de una transformación lineal.
Epimorfismo y monomorfismo.
Isomorfismo entre espacios vectoriales y espacios isomorfos.
Matriz de una transformación lineal con respecto a un par de bases dadas.
Autovalor, autovector y autoespacio.
Polinomio característico.


Propiedades, teoremas y resultados

Sistemas equivalentes de ecuaciones lineales tienen las mismas soluciones (Capítulo 1, Teorema 1.1.2).
La operación inversa de una operación elemental es otra operación elemental del mismo tipo (Capítulo 1, Teorema 1.1.2).
Sean A,B matrices m × n tal que A y B son equivalentes por filas. Entonces, los sistemas homogéneos AX = 0 y BX = 0 tiene las mismas soluciones (Capítulo 1, Teorema 1.2.2).
Toda matriz m × n es equivalente por filas a una matriz escalón reducida por fila (Capítulo 1, Teorema Teorema 1.2.3.).
Sea A matriz n × n con coeficientes en K. Entonces, si A es equivalente por filas a R una MERF y R tiene filas nulas, el sistema AX = 0 tiene más de una solución (Capítulo 1, Teorema 2.23).
Sea A una matriz m × n con m < n. Entonces, el sistema de ecuaciones lineales asociado a esta matriz tiene soluciones no triviales (Teorema 1.2.6).
Sea A una matriz n × n. Si A es equivalente por filas a la matriz identidad entonces el sistema AX = 0 tiene un única solución ("implica" de Teorema 1.2.8).
Si A inversible, entonces la inversa de A es inversible y su inversa es A (Teorema 1.5.2 (1)).
Si A y B son inversibles, entonces AB es inversible y (la inversa de ABes la inversa de B por la inversa de A (Teorema 1.5.2 (2)).
Una matriz elemental es inversible (Teorema 1.5.3).
Sea A matriz n  x  n, A es equivalente por filas a la matriz identidad, entonces A es producto de matrices elementales (parte del Teorema 1.5.4).
Sea A matriz n  x  n, A es producto de matrices elementales, entonces Aes inversible (parte del Teorema 1.5.4).
Si A es una matriz n × n, son equivalentes: A es inversible, el sistema homogéneo AX = 0 tiene solo la solución trivial, el sistema AX = Y tiene una solución para cada Y (Teorema 1.5.7).
Efecto de las operaciones elementales en el valor del determinante (Teorema 1.6.4, sólo enunciado, sin demostración).
Si A tiene dos filas iguales, entonces det A = 0 (Capítulo 1, Corolario 1.6.6(1)).
Si A tiene una fila nula, entonces det A = 0 (Capítulo 1, Corolario 1.6.6(2)).
El conjunto de las combinaciones lineales de k vectores es un subespacio vectorial (Teorema 2.2.2)
La suma de subespacios vectoriales es un subespacio vectorial (Teorema 2.2.5)
Si S es un subconjunto linealmente independiente de V y v no pertenecea a < S > entonces {S∪{v}} es linealmente independiente (Lema 2.3.4).
Se puede completar un conjunto LI a una base (Teorema 2.3.5, sólo enunciado, sin demostración).
La escritura en coordenadas de un vector está bien definida (Proposición 2.6.1)
El núcleo y la imagen de una transformación lineal son subespacios vectoriales (Teorema 3.2.1)
Dimensión del núcleo más dimensión de la imagen de una transformación lineal es igual a la dimensión del dominio (Teorema 3.2.2, sólo enunciado, sin demostración).
Sea T : V → W una transformación lineal. Entonces T es monomorfismo si y sólo si Nu(T) = 0 (Proposición 3.3.1).
Sea T un isomorfismo. Entonces la inversa de T es lineal e isomorfismo (Teorema 3.3.3).
Los autoespacios son subespacios vectoriales (Teorema 3.6.1).
Un conjunto de autovectores no nulos correspondientes a distintos autovalores es linealmente independiente (Teorema 3.6.2).
c es autovalor de T si y sólo si c es raíz del polinomio característico de T (Proposición 3.6.4).